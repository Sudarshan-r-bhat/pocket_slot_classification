from __future__ import absolute_import, division, print_function, unicode_literals
import numpy as np
import os
from keras.models import Sequential
from keras.layers import Dense, MaxPooling2D, Dropout, Conv2D, Flatten
from keras.preprocessing.image import ImageDataGenerator
from keras.optimizers import Adam
import cv2
import pathlib




'''
Note: ======> call resize_image() only once.

How to make directories?

0.) Make a root folder, say "image_detection"
1.) make a folder , say "raw" inside "image_detection" folder.
2.) Now "raw" should contain 2 folders "train", "test" , Each of these folders should contain folders called "pockets", "slots" containing appropriate images.
3.) Make a folder called "processed" to store resized images inside root folder "image_detection".
4.) Now "processed" directory should contain 2 folders "train", "test" , Each of these folders should contain folders called "pockets", "slots" .
5.) Done.

keep 90 images in train and 10 images in each of the test folders.

'''



# dataset path.
data_path = pathlib.Path("D:\\ML_datasets\\km_slot_pocket\\images\\valid\\")


def resize_image(path, path_2):
    file_list = os.listdir("D:\\ML_datasets\\km_slot_pocket\\train\\pockets")  # "D:\\image_detection\\raw\\train\\pockets" # follow the same for the below segments as well.
    save_loc = "D:\\ML_datasets\\km_slot_pocket\\images\\valid"	# "D:\\image_detection\\processed\\train"
    # resize train images
    try:
        for i, file in enumerate(file_list):
            img = cv2.imread(path + '\\pockets\\' + file, cv2.IMREAD_GRAYSCALE)
            r_img = cv2.resize(img, (200, 150))
            cv2.imwrite(save_loc + "\\pockets\\p_{}.bmp".format(i + 1), r_img)
            
    except Exception as e:
        print(str(e))
        pass
    file_list_2 = os.listdir("D:\\ML_datasets\\km_slot_pocket\\train\\slots")
    try:
        for i, file in enumerate(file_list_2):
            img = cv2.imread(path + '\\slots\\' + file, cv2.IMREAD_GRAYSCALE)
            r_img = cv2.resize(img, (200, 150))
            cv2.imwrite(save_loc + "\\slots\\s_{}.bmp".format(i + 1), r_img)
            # os.remove(path + '\\slots\\' + file)
    except Exception as e:
        print(str(e))
        pass

    # resize the test image_set.
    file_list_3 = os.listdir("D:\\ML_datasets\\km_slot_pocket\\test\\pockets")
    test_save_loc = "D:\\ML_datasets\\km_slot_pocket\\images\\test"
    try:
        for i, file in enumerate(file_list_3):
            img = cv2.imread(path_2 + '\\pockets\\' + file, cv2.IMREAD_GRAYSCALE)
            r_img = cv2.resize(img, (200, 150))
            cv2.imwrite(test_save_loc + "\\pockets\\p_{}.bmp".format(i + 1), r_img)
            # os.remove(path + '\\pockets\\' + file)
    except Exception as e:
        print(str(e))
        pass
    file_list_4 = os.listdir("D:\\ML_datasets\\km_slot_pocket\\test\\slots")
    try:
        for i, file in enumerate(file_list_4):
            img = cv2.imread(path_2 + '\\slots\\' + file, cv2.IMREAD_GRAYSCALE)
            r_img = cv2.resize(img, (200, 150))
            cv2.imwrite(test_save_loc + "\\slots\\s_{}.bmp".format(i + 1), r_img)
            # os.remove(path + '\\pockets\\' + file)
    except Exception as e:
        print(str(e))
        pass


def neural_net():
    class_names = ['pocket', 'slot']
    batch_size = 32
    img_height = 150
    img_width = 200

    # image generators.
    train_image_generator = ImageDataGenerator()
    test_image_generator = ImageDataGenerator()

    # data generated by the generators.
    train_data_gen = train_image_generator.flow_from_directory(directory="D:\\ML_datasets\\km_slot_pocket\\images\\valid",
                                                               batch_size=batch_size,
                                                               shuffle=True,
                                                               target_size=(150, 200),
                                                               class_mode='categorical')

    test_data_gen = test_image_generator.flow_from_directory(directory="D:\\ML_datasets\\km_slot_pocket\\images\\test",
                                                             batch_size=batch_size,
                                                             shuffle=True,
                                                             target_size=(150, 200),
                                                             class_mode='categorical')

    # model
    model = Sequential([
        Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=(img_height, img_width, 3)),
        MaxPooling2D(pool_size=(3, 3)),
        Conv2D(64, (3, 3), padding='same', activation='relu'),
        MaxPooling2D(pool_size=(3, 3)),
        Conv2D(128, (3, 3), padding='same', activation='relu'),
        MaxPooling2D(pool_size=(3, 3)),
        Flatten(),
        Dropout(0.3),
        Dense(units=512, activation='relu'),
        Dense(units=2, activation='softmax')
    ])

    opt = Adam()
    model.compile(optimizer=opt, loss="categorical_crossentropy", metrics=["accuracy"])
    model.fit_generator(generator=train_data_gen,
                        steps_per_epoch=180,
                        epochs=5,
                        shuffle=True,
                        validation_data=test_data_gen,
                        validation_steps=10)

    from keras.preprocessing import image
    path = 'D:\\ML_datasets\\km_slot_pocket\\images\\valid\\slots\\s_2.bmp'
    img = image.load_img(path, target_size=(150, 200))
    img = image.img_to_array(img)
    img = np.expand_dims(img, axis=0)
    pred = model.predict(img)
    index = np.argmax(pred[0])
    print('This Mechanical part could be a ', class_names[index])


# resize images.
train_path = "D:\\ML_datasets\\km_slot_pocket\\train"  # "D:\\image_detection\\raw\\train"  # for you're reference
test_path = "D:\\ML_datasets\\km_slot_pocket\\test"  # "D:\\image_detection\\raw\\test" 
resize_image(train_path, test_path)

neural_net()
